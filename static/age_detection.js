/* ===== ì¹´ë©”ë¼ ìë™ ì—°ë ¹ ê°ì§€ ê¸°ëŠ¥ (ë³µì›ë¨) ===== */
(function () {
    // face-api.js CDNì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    const faceapiAvailable = typeof faceapi !== 'undefined';

    const MODEL_URLS = [
        './static/models',
        'https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights'
    ];

    let camStream = null;
    let detectorEnabled = false;
    let modelLoaded = false;

    // DOM ìš”ì†Œ ì°¸ì¡°
    const $camOverlay = document.getElementById('camOverlay');
    const $camVideo = document.getElementById('camVideo');
    const $camCanvas = document.getElementById('camCanvas');
    const $camStatusText = document.getElementById('camStatusText');
    const $cameraStatus = document.getElementById('cameraStatus'); // ì‘ì€ ë°°ì§€

    // ì¹´ë©”ë¼ ì‹œì‘
    async function startAgeDetection() {
        if (camStream) return;

        try {
            // ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
            camStream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'user' },
                audio: false
            });

            console.log('ì¹´ë©”ë¼ ì‹œì‘ë¨');

            // ë¹„ë””ì˜¤ ìš”ì†Œì— ìŠ¤íŠ¸ë¦¼ ì—°ê²°
            if ($camVideo) {
                $camVideo.srcObject = camStream;
                // ì˜¤ë²„ë ˆì´ í‘œì‹œ
                if ($camOverlay) {
                    $camOverlay.classList.remove('cam-hidden');
                    $camOverlay.setAttribute('aria-hidden', 'false');
                }
            }

            updateStatus('ì¹´ë©”ë¼ ì‹¤í–‰ ì¤‘...');

            // face-api ëª¨ë¸ ë¡œë“œ
            if (faceapiAvailable && !modelLoaded) {
                updateStatus('ëª¨ë¸ ë¡œë”© ì¤‘...');
                await loadModels();
            }

            // ê°ì§€ ì‹œì‘
            if (modelLoaded) {
                detectorEnabled = true;
                runDetection();
            } else {
                updateStatus('ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨');
            }
        } catch (error) {
            console.error('ì¹´ë©”ë¼ ì‹œì‘ ì‹¤íŒ¨:', error);
            updateStatus('ì¹´ë©”ë¼ ì˜¤ë¥˜');
            alert('ì¹´ë©”ë¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
        }
    }

    // ìƒíƒœ ì—…ë°ì´íŠ¸ í—¬í¼
    function updateStatus(text) {
        if ($camStatusText) $camStatusText.textContent = `ì¹´ë©”ë¼: ${text}`;
        if ($cameraStatus) $cameraStatus.textContent = `ğŸ“· ${text}`;
    }

    // face-api ëª¨ë¸ ë¡œë“œ
    async function loadModels() {
        if (!faceapiAvailable) {
            console.warn('face-api.jsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
            return false;
        }

        for (const baseUrl of MODEL_URLS) {
            try {
                console.log(`ëª¨ë¸ ë¡œë”© ì‹œë„: ${baseUrl}`);
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri(baseUrl),
                    faceapi.nets.ageGenderNet.loadFromUri(baseUrl)
                ]);
                modelLoaded = true;
                console.log('ëª¨ë¸ ë¡œë“œ ì„±ê³µ:', baseUrl);
                return true;
            } catch (error) {
                console.warn(`ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ (${baseUrl}):`, error);
            }
        }

        console.error('ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì‹œë„ ì‹¤íŒ¨');
        return false;
    }

    // ì—°ë ¹ ê°ì§€ ì‹¤í–‰
    async function runDetection() {
        if (!$camVideo || !$camCanvas) return;

        const ctx = $camCanvas.getContext('2d');

        while (detectorEnabled && camStream) {
            try {
                if ($camVideo.readyState >= 2) {
                    // ìº”ë²„ìŠ¤ í¬ê¸° ë§ì¶¤
                    $camCanvas.width = $camVideo.videoWidth;
                    $camCanvas.height = $camVideo.videoHeight;
                    ctx.drawImage($camVideo, 0, 0, $camCanvas.width, $camCanvas.height);

                    // ì–¼êµ´ ê°ì§€ ë° ì—°ë ¹ ì¶”ì •
                    const detection = await faceapi
                        .detectSingleFace($camVideo, new faceapi.TinyFaceDetectorOptions())
                        .withAgeAndGender();

                    if (detection && detection.age) {
                        const estimatedAge = Math.round(detection.age);
                        const ageGroup = getAgeGroup(estimatedAge);

                        updateStatus(`ì¶”ì • ì—°ë ¹: ${estimatedAge}ì„¸ (${getAgeGroupName(ageGroup)})`);
                        console.log(`ì¶”ì •: ${estimatedAge}ì„¸ -> ${ageGroup}`);

                        // UI ì—…ë°ì´íŠ¸ (ì „ì—­ í•¨ìˆ˜ í˜¸ì¶œ)
                        if (typeof selectAge === 'function') {
                            // ë„ˆë¬´ ì¦ì€ ë³€ê²½ ë°©ì§€ ë¡œì§ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
                            selectAge(ageGroup);
                        }
                    } else {
                        updateStatus('ì–¼êµ´ ì°¾ëŠ” ì¤‘...');
                    }
                }
            } catch (error) {
                console.error('ì–¼êµ´ ê°ì§€ ì˜¤ë¥˜:', error);
            }

            // 1ì´ˆë§ˆë‹¤ ê°ì§€
            await new Promise(resolve => setTimeout(resolve, 1000));
        }
    }

    // ì—°ë ¹ëŒ€ ê²°ì •
    function getAgeGroup(age) {
        if (age <= 12) return 'child';
        if (age <= 19) return 'teen';
        if (age <= 64) return 'adult';
        return 'senior';
    }

    function getAgeGroupName(group) {
        const names = {
            'child': 'ì–´ë¦°ì´',
            'teen': 'ì²­ì†Œë…„',
            'adult': 'ì„±ì¸',
            'senior': 'ë…¸ì¸'
        };
        return names[group] || group;
    }

    // ì¹´ë©”ë¼ ì¤‘ì§€
    function stopAgeDetection() {
        detectorEnabled = false;
        if (camStream) {
            camStream.getTracks().forEach(track => track.stop());
            camStream = null;
        }

        if ($camOverlay) {
            $camOverlay.classList.add('cam-hidden');
            $camOverlay.setAttribute('aria-hidden', 'true');
        }

        updateStatus('ë¹„í™œì„±');
        console.log('ì¹´ë©”ë¼ ì¤‘ì§€ë¨');
    }

    // ì „ì—­ í•¨ìˆ˜ë¡œ ë…¸ì¶œ
    window.startAgeDetection = startAgeDetection;
    window.stopAgeDetection = stopAgeDetection;
})();
